# -*- coding: utf-8 -*-
"""ecg.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GbCsuRq6kffjlrSwE5PpF4H5s0Pvvhmo
"""

!pip install wfdb neurokit2 torch torchvision torchaudio

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import wfdb
import neurokit2 as nk

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

record_name = "100"
record = wfdb.rdrecord(record_name, pn_dir="mitdb")

signal = record.p_signal[:, 0]  # Lead MLII
fs = record.fs

print("Sampling rate:", fs)
print("Signal length:", signal.shape)

plt.figure(figsize=(15,4))
plt.plot(signal[:3000])
plt.title("Raw ECG Signal (MIT-BIH Record 100)")
plt.xlabel("Samples")
plt.ylabel("Amplitude (mV)")
plt.grid(True)
plt.show()

"""## Dataset Overview

The MIT-BIH Arrhythmia Database is a widely used benchmark dataset for ECG analysis.
Signals are sampled at 360 Hz and annotated by clinical experts. In this project, the MLII lead is used due to its clinical relevance and widespread adoption in arrhythmia detection studies.

"""

from scipy.signal import butter, filtfilt

def bandpass_filter(signal, fs, lowcut=0.5, highcut=40, order=4):
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype="band")
    return filtfilt(b, a, signal)

filtered_ecg = bandpass_filter(signal, fs)

cleaned_ecg = nk.ecg_clean(filtered_ecg, sampling_rate=fs, method="neurokit")

plt.figure(figsize=(15,5))
plt.plot(signal[:3000], label="Raw ECG", alpha=0.5)
plt.plot(cleaned_ecg[:3000], label="Cleaned ECG", linewidth=2)
plt.legend()
plt.title("Raw vs Cleaned ECG Signal")
plt.xlabel("Samples")
plt.ylabel("Amplitude (mV)")
plt.grid(True)
plt.show()

signals, info = nk.ecg_peaks(cleaned_ecg, sampling_rate=fs)
r_peaks = info["ECG_R_Peaks"]

print("Number of detected R-peaks:", len(r_peaks))

plt.figure(figsize=(15,5))
plt.plot(cleaned_ecg[:3000], label="Cleaned ECG")
plt.scatter(
    r_peaks[r_peaks < 3000],
    cleaned_ecg[r_peaks[r_peaks < 3000]],
    color="red",
    s=20,
    label="R-peaks"
)
plt.legend()
plt.title("R-Peak Detection on Cleaned ECG")
plt.xlabel("Samples")
plt.ylabel("Amplitude (mV)")
plt.grid(True)
plt.show()

"""## ECG Signal Preprocessing

Raw ECG signals were preprocessed using a combination of bandpass filtering and signal cleaning techniques to remove baseline wander and high-frequency noise. R-peaks were detected using a Pan–Tompkins-inspired algorithm to enable accurate heartbeat segmentation for downstream deep learning analysis.

"""

pre_r = int(0.2 * fs)
post_r = int(0.4 * fs)
window_size = pre_r + post_r

print("Window size (samples):", window_size)

beats = []

for r in r_peaks:
    start = r - pre_r
    end = r + post_r

    if start >= 0 and end < len(cleaned_ecg):
        beat = cleaned_ecg[start:end]
        beats.append(beat)

beats = np.array(beats)
print("Total beats extracted:", beats.shape)

plt.figure(figsize=(12,6))

for i in range(5):
    plt.plot(beats[i], label=f"Beat {i}")

plt.title("Sample ECG Beats (Segmented)")
plt.xlabel("Samples")
plt.ylabel("Amplitude")
plt.legend()
plt.grid(True)
plt.show()

beats_norm = (beats - np.mean(beats, axis=1, keepdims=True)) / (
    np.std(beats, axis=1, keepdims=True) + 1e-8
)

X = torch.tensor(beats_norm, dtype=torch.float32)
X = X.unsqueeze(1)

print("Tensor shape:", X.shape)

class ECGBeatDataset(Dataset):
    def __init__(self, signals):
        self.signals = signals

    def __len__(self):
        return self.signals.shape[0]

    def __getitem__(self, idx):
        return self.signals[idx]

dataset = ECGBeatDataset(X)

dataloader = DataLoader(
    dataset,
    batch_size=32,
    shuffle=True
)

batch = next(iter(dataloader))
batch.shape

"""## Beat Segmentation and Dataset Construction

Each ECG signal was segmented into individual heartbeats centered around detected R-peaks. Fixed-length windows were extracted to ensure consistent input dimensions for deep learning models. Beat-level normalization was applied to preserve morphological patterns while reducing inter-beat amplitude variability.

"""

annotation = wfdb.rdann(record_name, "atr", pn_dir="mitdb")

ann_samples = annotation.sample
ann_symbols = annotation.symbol

print("Total annotations:", len(ann_symbols))

arrhythmia_symbols = [
    "V",  # PVC
    "A",  # Atrial premature
    "L", "R",  # Bundle branch blocks
    "F",  # Fusion
    "E"   # Ventricular escape
]

labels = []

valid_r_peaks = []

for r in r_peaks:
    start = r - pre_r
    end = r + post_r

    if start >= 0 and end < len(cleaned_ecg):
        idx = np.argmin(np.abs(ann_samples - r))
        symbol = ann_symbols[idx]

        label = 1 if symbol in arrhythmia_symbols else 0

        labels.append(label)
        valid_r_peaks.append(r)

labels = np.array(labels)

print("Label distribution:", np.bincount(labels))

print("X shape:", X.shape)
print("y shape:", labels.shape)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X,
    labels,
    test_size=0.2,
    random_state=42,
    stratify=labels
)

print("Train:", X_train.shape, "Test:", X_test.shape)

class ECGBeatDataset(Dataset):
    def __init__(self, signals, labels):
        self.signals = signals
        self.labels = torch.tensor(labels, dtype=torch.long)

    def __len__(self):
        return self.signals.shape[0]

    def __getitem__(self, idx):
        return self.signals[idx], self.labels[idx]

train_dataset = ECGBeatDataset(X_train, y_train)
test_dataset = ECGBeatDataset(X_test, y_test)

train_loader = DataLoader(
    train_dataset,
    batch_size=32,
    shuffle=True
)

test_loader = DataLoader(
    test_dataset,
    batch_size=32,
    shuffle=False
)

"""## Beat-Level Labeling and Dataset Split

Each segmented heartbeat was labeled based on expert annotations provided in the MIT-BIH database. Beats were categorized into normal and arrhythmic classes. The dataset was split into training and test sets using stratified sampling to preserve class distribution and prevent data leakage.
"""

class ECGCNN(nn.Module):
    def __init__(self):
        super(ECGCNN, self).__init__()

        self.conv1 = nn.Conv1d(1, 16, kernel_size=7, padding=3)
        self.bn1 = nn.BatchNorm1d(16)

        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, padding=2)
        self.bn2 = nn.BatchNorm1d(32)

        self.pool = nn.MaxPool1d(2)
        self.gap = nn.AdaptiveAvgPool1d(1)

        self.fc = nn.Linear(32, 2)

    def forward(self, x):
        x = self.pool(torch.relu(self.bn1(self.conv1(x))))
        x = self.pool(torch.relu(self.bn2(self.conv2(x))))
        x = self.gap(x)
        x = x.view(x.size(0), -1)
        return self.fc(x)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = ECGCNN().to(device)
print(model)

sample_batch, _ = next(iter(train_loader))
sample_batch = sample_batch.to(device)

out = model(sample_batch)
print("Output shape:", out.shape)

class_counts = np.bincount(y_train)
class_weights = 1.0 / class_counts
class_weights = class_weights / class_weights.sum()

weights = torch.tensor(class_weights, dtype=torch.float32).to(device)

criterion = nn.CrossEntropyLoss(weight=weights)

optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

def train_epoch(model, loader):
    model.train()
    total_loss = 0

    for x, y in loader:
        x, y = x.to(device), y.to(device)

        optimizer.zero_grad()
        outputs = model(x)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    return total_loss / len(loader)

from sklearn.metrics import classification_report

def evaluate(model, loader):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            outputs = model(x)
            preds = torch.argmax(outputs, dim=1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(y.cpu().numpy())

    print(classification_report(all_labels, all_preds, digits=4))

num_epochs = 10

for epoch in range(num_epochs):
    loss = train_epoch(model, train_loader)
    print(f"Epoch [{epoch+1}/{num_epochs}] - Loss: {loss:.4f}")

print("\nTest set evaluation:")
evaluate(model, test_loader)

"""## Deep Learning Model

A 1D convolutional neural network was employed to learn discriminative patterns from beat-level ECG segments. Class imbalance was addressed using weighted cross-entropy loss. The proposed architecture was intentionally kept compact to reduce overfitting while maintaining interpretability for explainable AI analysis.

"""

gradients = None
activations = None

def backward_hook(module, grad_input, grad_output):
    global gradients
    gradients = grad_output[0]

def forward_hook(module, input, output):
    global activations
    activations = output

model.conv2.register_forward_hook(forward_hook)
model.conv2.register_backward_hook(backward_hook)

model.eval()

for x, y in test_loader:
    x, y = x.to(device), y.to(device)
    outputs = model(x)
    preds = torch.argmax(outputs, dim=1)

    idx = (preds == 1).nonzero(as_tuple=True)[0]
    if len(idx) > 0:
        beat = x[idx[0]].unsqueeze(0)
        label = y[idx[0]].item()
        break

print("True label:", label)

model.zero_grad()
output = model(beat)
score = output[0, 1]
score.backward()

weights = torch.mean(gradients, dim=2)
cam = torch.sum(weights[:, :, None] * activations, dim=1)
cam = torch.relu(cam)
cam = cam.squeeze().cpu().detach().numpy()

cam = cam / np.max(cam)

import cv2

signal_length = beat.shape[-1]

cam_resized = np.interp(
    np.linspace(0, len(cam) - 1, signal_length),
    np.arange(len(cam)),
    cam
)

signal = beat.squeeze().cpu().numpy()

plt.figure(figsize=(12,4))
plt.plot(signal, label="ECG Beat", color="black")

plt.scatter(
    range(len(signal)),
    signal,
    c=cam_resized,
    cmap="jet",
    s=10,
    label="Grad-CAM"
)

plt.colorbar(label="Importance")
plt.title("Grad-CAM Explanation for ECG Beat")
plt.xlabel("Time")
plt.ylabel("Amplitude")
plt.show()

"""## Explainability via Grad-CAM

Grad-CAM was employed to interpret the predictions of the deep learning model at the waveform level. The resulting heatmaps highlight critical temporal regions of the ECG signal that contribute most strongly to arrhythmia classification decisions. Notably, the model focuses on regions corresponding to abnormal QRS morphology, aligning with established clinical knowledge.

"""

plt.figure(figsize=(12,4))
plt.plot(signal, label="ECG Beat", color="black")

plt.scatter(
    range(len(signal)),
    signal,
    c=cam_resized,
    cmap="jet",
    s=10
)

plt.colorbar(label="Grad-CAM Importance")
plt.title("Grad-CAM Explanation for ECG Beat")
plt.xlabel("Time")
plt.ylabel("Amplitude")

plt.tight_layout()
plt.savefig("gradcam_ecg_beat.png", dpi=300)
plt.show()

def compute_gradcam(model, beat, target_class):
    global gradients, activations

    model.zero_grad()
    output = model(beat)
    score = output[0, target_class]
    score.backward()

    weights = torch.mean(gradients, dim=2)
    cam = torch.sum(weights[:, :, None] * activations, dim=1)
    cam = torch.relu(cam)
    cam = cam.squeeze().cpu().detach().numpy()

    cam = cam / np.max(cam)

    signal_length = beat.shape[-1]
    cam_resized = np.interp(
        np.linspace(0, len(cam) - 1, signal_length),
        np.arange(len(cam)),
        cam
    )

    return cam_resized

model.eval()

normal_beat = None
arrhythmia_beat = None

for x, y in test_loader:
    x, y = x.to(device), y.to(device)
    outputs = model(x)
    preds = torch.argmax(outputs, dim=1)

    for i in range(len(y)):
        if y[i] == 0 and normal_beat is None:
            normal_beat = x[i].unsqueeze(0)
        if y[i] == 1 and preds[i] == 1 and arrhythmia_beat is None:
            arrhythmia_beat = x[i].unsqueeze(0)

    if normal_beat is not None and arrhythmia_beat is not None:
        break

if arrhythmia_beat is None:
    for x, y in test_loader:
        x, y = x.to(device), y.to(device)
        outputs = model(x)
        preds = torch.argmax(outputs, dim=1)

        for i in range(len(y)):
            if preds[i] == 1:
                arrhythmia_beat = x[i].unsqueeze(0)
                break
        if arrhythmia_beat is not None:
            break

cam_normal = compute_gradcam(model, normal_beat, target_class=0)
cam_arrhythmia = compute_gradcam(model, arrhythmia_beat, target_class=1)

signal_normal = normal_beat.squeeze().cpu().numpy()
signal_arrhythmia = arrhythmia_beat.squeeze().cpu().numpy()

fig, axes = plt.subplots(2, 1, figsize=(12,6), sharex=True)
axes[0].plot(signal_normal, color="black")
sc0 = axes[0].scatter(
    range(len(signal_normal)),
    signal_normal,
    c=cam_normal,
    cmap="jet",
    s=10
)
axes[0].set_title("Normal ECG Beat – Grad-CAM")
axes[0].set_ylabel("Amplitude")

axes[1].plot(signal_arrhythmia, color="black")
sc1 = axes[1].scatter(
    range(len(signal_arrhythmia)),
    signal_arrhythmia,
    c=cam_arrhythmia,
    cmap="jet",
    s=10
)
axes[1].set_title("Arrhythmic ECG Beat – Grad-CAM")
axes[1].set_xlabel("Time")
axes[1].set_ylabel("Amplitude")

fig.colorbar(sc1, ax=axes, label="Grad-CAM Importance")
plt.savefig("gradcam_comparison_normal_vs_arrhythmia.png", dpi=300)
plt.show()

"""
Thank you for taking the time to explore this project, run the code, and review the implementation.  
Your feedback, suggestions, and contributions are greatly appreciated and can help improve this project.
 follow me on...

Linkedin : www.linkedin.com/in/ali-mohamaadpour"""